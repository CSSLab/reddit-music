{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Custom Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A central result of our research is the 'social genres' we were able to create. For this we used the Reddit embedding alongside a hierarchical model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\Venia\\Desktop\\reddit_music')\n",
    "\n",
    "\n",
    "# these files were removed\n",
    "metadata=pd.read_table('data\\\\reddit-master-metadata.tsv')\n",
    "vectors=pd.read_table(\"data\\\\reddit-master-vectors.tsv\",names=list(range(150)))\n",
    "metadata=metadata['community']\n",
    "\n",
    "\n",
    "data=pd.merge(metadata,vectors,left_index=True,right_index=True)\n",
    "\n",
    "\n",
    "# Reddit_Sub_Com_v4_clean was the dataset before classification was conducted to get the genres. I recommend you use the RedditMusic dataset to classify differently. \n",
    "df = pd.read_csv(\"data\\\\Reddit_Sub_Com_v4_clean.csv\")\n",
    "df = df.drop_duplicates(subset=['id'])\n",
    "artist_counts = df.groupby('artist')['score'].count()\n",
    "artist_counts = artist_counts.reset_index()\n",
    "artist_counts.columns = ['artist','count']\n",
    "artist_counts.to_csv(\"data\\\\artist_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genres(df, n_clusters=50,with_ppmi=False):\n",
    "    \"\"\"df should be subreddit artist and ppmi. Columns should be ['subreddit','artist','ppmi'] \"\"\"\n",
    "\n",
    "    global data \n",
    "    if with_ppmi==False:\n",
    "        df=df[['subreddit','artist']]\n",
    "        \n",
    "        merged=pd.merge(df,data,left_on='subreddit',right_on='community')\n",
    "        if len(merged) != len(df):\n",
    "            print(\"we may have a problem\")\n",
    "\n",
    "        count=merged.groupby('artist')['artist'].count()\n",
    "        artist=merged.groupby('artist')[list(range(150))].mean()\n",
    "\n",
    "        #only take artists with 20 or more shares \n",
    "        a_index=count[count>20].index\n",
    "        artist=artist.loc[artist.index.isin(a_index)]\n",
    "\n",
    "        # use hierarchical clustering\n",
    "        ac=AgglomerativeClustering(n_clusters)\n",
    "\n",
    "        ac.fit(artist)\n",
    "        artist['label']=ac.labels_\n",
    "        return artist, ac \n",
    "    elif with_ppmi==True:\n",
    "        df=df[['subreddit','artist', 'ppmi']]\n",
    "        merged=pd.merge(df,data,left_on='subreddit',right_on='community')\n",
    "        for j in range(150):\n",
    "            merged[j]=merged['ppmi']*merged[j]\n",
    "        count=merged.groupby('artist')['artist'].count()\n",
    "        artist=merged.groupby('artist')[list(range(150))].mean()\n",
    "\n",
    "        #only take artists with 20 or more shares \n",
    "        a_index=count[count>20].index\n",
    "        artist=artist.loc[artist.index.isin(a_index)]\n",
    "\n",
    "        # use hierarchical clustering\n",
    "        ac=AgglomerativeClustering(n_clusters)\n",
    "\n",
    "        ac.fit(artist)\n",
    "        artist['label']=ac.labels_\n",
    "        return artist, ac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom, ac = create_genres(df, 50, with_ppmi=False)\n",
    "custom=custom.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom.to_csv(\"data\\\\derived_data\\\\Artist_Vectors.csv\")\n",
    "\n",
    "\n",
    "custom[['artist','label']].to_csv(\"data\\\\derived_data\\\\Artist_Genre.csv\")\n",
    "\n",
    "custom.groupby('label')[list(range(150))].mean().to_csv(\"Genre_Vectors.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\agglogomerative_f.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "from joblib import dump, load\n",
    "dump(ac, 'data\\\\derived_data\\\\agglogomerative_f.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new finalized dataset\n",
    "data4=pd.merge(df,custom[['artist','label']], on = 'artist')\n",
    "data4 = data4[['score','link_id','author','subreddit','created_utc','id','parent_id','track_id','artist','track_name','link','youtube_id','class','url','album_id','label']]\n",
    "\n",
    "# also known as the RedditMusic dataset. \n",
    "data4.to_csv(\"data\\\\Reddit_Sub_Com_f_genre.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Rick Astley              98300\n",
       "Luis Fonsi               16180\n",
       "Queen                     9129\n",
       "The Lonely Island         6750\n",
       "Kanye West                6497\n",
       "Eminem                    5260\n",
       "\"Weird Al\" Yankovic       4589\n",
       "Muse                      4431\n",
       "Daft Punk                 4413\n",
       "Radiohead                 4209\n",
       "Metallica                 4052\n",
       "Gorillaz                  3506\n",
       "Pink Floyd                3440\n",
       "Lemon Demon               3258\n",
       "Simon & Garfunkel         3202\n",
       "Childish Gambino          3176\n",
       "Weezer                    3145\n",
       "Tame Impala               2995\n",
       "Red Hot Chili Peppers     2926\n",
       "Girls' Generation         2878\n",
       "Foo Fighters              2872\n",
       "Linkin Park               2822\n",
       "Michael Jackson           2798\n",
       "Sabaton                   2769\n",
       "Rebecca Black             2750\n",
       "Quindon Tarver            2741\n",
       "Coldplay                  2738\n",
       "Europe                    2685\n",
       "Johnny Cash               2644\n",
       "Kendrick Lamar            2636\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.groupby('artist')['artist'].count().sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data\\\\derived_data\\\\Artist_Vectors.csv\")\n",
    "gens = pd.read_csv(\"data\\\\derived_data\\\\genre_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data,gens, on ='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = data[['artist','genre']]\n",
    "vectors = data[[str(k) for k in range(150)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.to_csv(\"data/derived_data/artist-vector.tsv\", index = False, sep='\\t', header=False)\n",
    "metadata.to_csv(\"data/derived_data/artist-metadata.tsv\", index = False, sep='\\t', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
